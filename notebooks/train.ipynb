{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path(os.getcwd()).parent\n",
    "\n",
    "data_dir = root_dir/'data'\n",
    "processed_data_dir = data_dir/'1_processed'\n",
    "prediction_dir = data_dir/'2_predictions'\n",
    "yaml_dir = processed_data_dir/'custom_data.yaml'\n",
    "\n",
    "runs_dir = root_dir/'runs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_project = 'custom_runs' # custom run directory\n",
    "data_version = \"3.0\" # for custom run name\n",
    "\n",
    "base_model = \"yolov8m.pt\"\n",
    "base_model_size = base_model.split('.')[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_start = 'pretrained'\n",
    "if model_start == 'pretrained':\n",
    "    pretrained_flag = True\n",
    "else:\n",
    "    pretrained_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_project_dir = root_dir / train_project\n",
    "if cont:\n",
    "    runs_list = os.listdir(custom_project_dir)\n",
    "    last_run = runs_list[-1]\n",
    "else:\n",
    "    # create custom run directory\n",
    "    if not os.path.exists(custom_project_dir):\n",
    "        os.makedirs(custom_project_dir)\n",
    "\n",
    "    # get the list of run\n",
    "    runs_list = os.listdir(custom_project_dir)\n",
    "\n",
    "    # create custom run name\n",
    "    if not runs_list:\n",
    "        train_name = f\"0_{data_version}_{model_start}_{base_model_size}\"\n",
    "    else:\n",
    "        last_run = max([int(order.split('_')[0]) for order in runs_list])\n",
    "        new_run = last_run + 1\n",
    "        train_name = f\"{new_run}_{data_version}_{model_start}_{base_model_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.207 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200  Python-3.9.18 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\\weights\\last.pt, data=d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\data\\1_processed\\custom_data.yaml, epochs=300, patience=10, batch=12, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs, name=2_3.0_pretrained_m, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3778012  ultralytics.nn.modules.head.Detect           [4, [192, 384, 576]]          \n",
      "Model summary: 295 layers, 25858636 parameters, 25858620 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 475/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\data\\1_processed\\train\\labels.cache... 16117 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16117/16117 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\data\\1_processed\\valid\\labels.cache... 4111 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4111/4111 [00:00<?, ?it/s]\n",
      "Plotting labels to d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00046875), 83 bias(decay=0.0)\n",
      "Resuming training from d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\\weights\\last.pt from epoch 81 to 300 total epochs\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1md:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     81/300      5.43G       1.42      1.187      1.388          0        640: 100%|██████████| 1344/1344 [10:33<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:15<00:00,  2.29it/s]\n",
      "                   all       4111       8921      0.641       0.61      0.638      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     82/300      5.42G       1.45      1.225       1.41          0        640: 100%|██████████| 1344/1344 [12:14<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:14<00:00,  2.32it/s]\n",
      "                   all       4111       8921      0.641      0.611      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     83/300      5.42G      1.448      1.227      1.408          1        640: 100%|██████████| 1344/1344 [12:06<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:15<00:00,  2.28it/s]\n",
      "                   all       4111       8921      0.638      0.615      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     84/300      5.45G      1.452      1.228      1.411          0        640: 100%|██████████| 1344/1344 [12:11<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:16<00:00,  2.25it/s]\n",
      "                   all       4111       8921      0.636      0.616      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     85/300      5.45G      1.455      1.232      1.415          6        640: 100%|██████████| 1344/1344 [12:18<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:16<00:00,  2.24it/s]\n",
      "                   all       4111       8921      0.634      0.616      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     86/300      5.43G       1.45      1.233      1.409          3        640: 100%|██████████| 1344/1344 [12:29<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:17<00:00,  2.23it/s]\n",
      "                   all       4111       8921      0.636      0.618      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     87/300      5.27G      1.446      1.226      1.408          1        640: 100%|██████████| 1344/1344 [12:10<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:15<00:00,  2.28it/s]\n",
      "                   all       4111       8921      0.635      0.618      0.638      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     88/300      5.26G      1.442      1.221      1.401          1        640: 100%|██████████| 1344/1344 [11:58<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:16<00:00,  2.26it/s]\n",
      "                   all       4111       8921      0.634       0.62      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     89/300      5.44G      1.448      1.208      1.409          1        640: 100%|██████████| 1344/1344 [13:06<00:00,  1.71it/s] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  23%|██▎       | 39/172 [00:28<00:54,  2.44it/s]WARNING  NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:29<00:00,  1.91it/s]\n",
      "                   all       4111       8921      0.633       0.62      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     90/300      5.46G      1.438      1.212      1.403          7        640: 100%|██████████| 1344/1344 [18:38<00:00,  1.20it/s] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  65%|██████▌   | 112/172 [00:59<00:24,  2.40it/s]WARNING  NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  73%|███████▎  | 126/172 [01:06<00:19,  2.39it/s]WARNING  NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:32<00:00,  1.86it/s]\n",
      "                   all       4111       8921      0.638      0.615      0.635       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     91/300      5.43G      1.443      1.202      1.408          2        640: 100%|██████████| 1344/1344 [11:26<00:00,  1.96it/s] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  72%|███████▏  | 123/172 [01:28<02:17,  2.80s/it]WARNING  NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:48<00:00,  1.59it/s]\n",
      "                   all       4111       8921      0.639      0.616      0.637      0.321\n",
      "Stopping training early as no improvement observed in last 10 epochs. Best results observed at epoch 81, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "11 epochs completed in 2.625 hours.\n",
      "Optimizer stripped from d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\\weights\\last.pt, 52.0MB\n",
      "Optimizer stripped from d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\\weights\\best.pt, 52.0MB\n",
      "\n",
      "Validating d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.200  Python-3.9.18 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 218 layers, 25842076 parameters, 0 gradients, 78.7 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/172 [00:00<?, ?it/s]WARNING  NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   2%|▏         | 4/172 [00:05<03:23,  1.21s/it]WARNING  NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:12<00:00,  2.37it/s]\n",
      "                   all       4111       8921       0.64      0.608      0.635       0.32\n",
      "       retak_memanjang       4111       2968      0.624      0.644      0.665      0.374\n",
      "       retak_melintang       4111       1836      0.601      0.577      0.588      0.268\n",
      "           retak_buaya       4111       2210      0.676      0.654      0.692      0.365\n",
      "               pothole       4111       1907      0.657      0.558      0.593      0.273\n",
      "Speed: 0.4ms preprocess, 9.7ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1md:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if cont:\n",
    "    # Load a model\n",
    "    model = YOLO(custom_project_dir / last_run / 'weights' / 'last.pt')  # load a partially trained model\n",
    "\n",
    "    # Resume training\n",
    "    results = model.train(resume=True)\n",
    "else:\n",
    "    # Load a model\n",
    "    model = YOLO(\n",
    "        base_model\n",
    "        )\n",
    "\n",
    "    # train the model\n",
    "    results = model.train(\n",
    "        data=yaml_dir,\n",
    "        epochs=300,\n",
    "        batch=12,\n",
    "        patience=10,\n",
    "        project=custom_project_dir,\n",
    "        name=train_name,\n",
    "        pretrained=pretrained_flag\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained YOLOv8n model\n",
    "best_model = YOLO(custom_project_dir / train_name / \"weights\" / \"best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = [str(prediction_dir / \"original\" / file) for file in os.listdir(prediction_dir / \"original\")]\n",
    "\n",
    "pred_location = prediction_dir / train_name\n",
    "if not os.path.exists(pred_location):\n",
    "    os.makedirs(pred_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 retak_buaya, 1: 640x640 2 retak_memanjangs, 2: 640x640 3 retak_memanjangs, 3: 640x640 (no detections), 4: 640x640 1 retak_buaya, 5: 640x640 (no detections), 6: 640x640 (no detections), 7: 640x640 3 retak_buayas, 8: 640x640 (no detections), 9: 640x640 (no detections), 10: 640x640 (no detections), 11: 640x640 (no detections), 12: 640x640 (no detections), 13: 640x640 4 retak_memanjangs, 14: 640x640 2 retak_memanjangs, 15: 640x640 (no detections), 16: 640x640 (no detections), 290.2ms\n",
      "Speed: 4.5ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Run inference on an image\n",
    "results = best_model(\n",
    "    source = pred_data\n",
    ")  # list of 1 Results object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    # im.show()  # show image\n",
    "    im.save(pred_location / ('pred_'+Path(r.path).name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r\"D:\\0_amri_local\\14_pupr_roaddamagedetection\\data\\PUPR\\Banten\\21017 R1.mp4\"\n",
    "video_path_out = r\"D:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\notebooks\\out.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "ret, frame = cap.read()\n",
    "H, W, _ = frame.shape\n",
    "out = cv2.VideoWriter(video_path_out, cv2.VideoWriter_fourcc(*'MP4V'), int(cap.get(cv2.CAP_PROP_FPS)), (W, H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "while ret:\n",
    "\n",
    "    results = best_model(frame)[0]\n",
    "\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = result\n",
    "\n",
    "        if score > threshold:\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
    "            cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "    out.write(frame)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8_custom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
