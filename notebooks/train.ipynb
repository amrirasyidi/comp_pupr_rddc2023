{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path(os.getcwd()).parent\n",
    "\n",
    "data_dir = root_dir/'data'\n",
    "processed_data_dir = data_dir/'1_processed'\n",
    "prediction_dir = data_dir/'2_predictions'\n",
    "yaml_dir = processed_data_dir/'custom_data.yaml'\n",
    "\n",
    "runs_dir = root_dir/'runs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_project = 'custom_runs' # custom run directory\n",
    "data_version = \"3.0\" # for custom run name\n",
    "\n",
    "base_model = \"yolov8m.pt\"\n",
    "base_model_size = base_model.split('.')[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_start = 'pretrained'\n",
    "if model_start == 'pretrained':\n",
    "    pretrained_flag = True\n",
    "else:\n",
    "    pretrained_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_project_dir = root_dir / train_project\n",
    "if cont:\n",
    "    runs_list = os.listdir(custom_project_dir)\n",
    "    last_run = runs_list[-1]\n",
    "else:\n",
    "    # create custom run directory\n",
    "    if not os.path.exists(custom_project_dir):\n",
    "        os.makedirs(custom_project_dir)\n",
    "\n",
    "    # get the list of run\n",
    "    runs_list = os.listdir(custom_project_dir)\n",
    "\n",
    "    # create custom run name\n",
    "    if not runs_list:\n",
    "        train_name = f\"0_{data_version}_{model_start}_{base_model_size}\"\n",
    "    else:\n",
    "        last_run = max([int(order.split('_')[0]) for order in runs_list])\n",
    "        new_run = last_run + 1\n",
    "        train_name = f\"{new_run}_{data_version}_{model_start}_{base_model_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.205 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200  Python-3.9.18 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\\weights\\last.pt, data=d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\data\\1_processed\\custom_data.yaml, epochs=300, patience=10, batch=12, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs, name=2_3.0_pretrained_m, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3778012  ultralytics.nn.modules.head.Detect           [4, [192, 384, 576]]          \n",
      "Model summary: 295 layers, 25858636 parameters, 25858620 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 475/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\data\\1_processed\\train\\labels.cache... 16117 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16117/16117 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\data\\1_processed\\valid\\labels.cache... 4111 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4111/4111 [00:00<?, ?it/s]\n",
      "Plotting labels to d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00046875), 83 bias(decay=0.0)\n",
      "Resuming training from d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\\weights\\last.pt from epoch 41 to 300 total epochs\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1md:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/300      5.38G      1.495      1.365       1.47         31        640:   4%|▍         | 58/1344 [00:22<08:10,  2.62it/s] \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 2.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"c:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\ultralytics\\data\\dataset.py\", line 183, in collate_fn\n    value = torch.stack(value, 0)\nRuntimeError: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 14745600 bytes.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\notebooks\\train.ipynb Cell 9\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model \u001b[39m=\u001b[39m YOLO(custom_project_dir \u001b[39m/\u001b[39m last_run \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlast.pt\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# load a partially trained model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# Resume training\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain(resume\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# Load a model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     model \u001b[39m=\u001b[39m YOLO(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         base_model\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\ultralytics\\engine\\model.py:341\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel\n\u001b[0;32m    340\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mhub_session \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession  \u001b[39m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 341\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    342\u001b[0m \u001b[39m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m RANK \u001b[39min\u001b[39;00m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\ultralytics\\engine\\trainer.py:192\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    189\u001b[0m         ddp_cleanup(\u001b[39mself\u001b[39m, \u001b[39mstr\u001b[39m(file))\n\u001b[0;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_train(world_size)\n",
      "File \u001b[1;32mc:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\ultralytics\\engine\\trainer.py:326\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtloss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m--> 326\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m pbar:\n\u001b[0;32m    327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_callbacks(\u001b[39m'\u001b[39m\u001b[39mon_train_batch_start\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    328\u001b[0m     \u001b[39m# Warmup\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\ultralytics\\data\\build.py:42\u001b[0m, in \u001b[0;36mInfiniteDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a sampler that repeats indefinitely.\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)):\n\u001b[1;32m---> 42\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n",
      "File \u001b[1;32mc:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1344\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[1;32mc:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1371\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m   1372\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\torch\\_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    642\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 2.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"c:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\ultralytics\\data\\dataset.py\", line 183, in collate_fn\n    value = torch.stack(value, 0)\nRuntimeError: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 14745600 bytes.\n"
     ]
    }
   ],
   "source": [
    "if cont:\n",
    "    # Load a model\n",
    "    model = YOLO(custom_project_dir / last_run / 'weights' / 'last.pt')  # load a partially trained model\n",
    "\n",
    "    # Resume training\n",
    "    results = model.train(resume=True)\n",
    "else:\n",
    "    # Load a model\n",
    "    model = YOLO(\n",
    "        base_model\n",
    "        )\n",
    "\n",
    "    # train the model\n",
    "    results = model.train(\n",
    "        data=yaml_dir,\n",
    "        epochs=300,\n",
    "        batch=12,\n",
    "        patience=10,\n",
    "        project=custom_project_dir,\n",
    "        name=train_name,\n",
    "        pretrained=pretrained_flag\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained YOLOv8n model\n",
    "best_model = YOLO(custom_project_dir / train_name / \"weights\" / \"best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = [str(prediction_dir / \"original\" / file) for file in os.listdir(prediction_dir / \"original\")]\n",
    "\n",
    "pred_location = prediction_dir / train_name\n",
    "if not os.path.exists(pred_location):\n",
    "    os.makedirs(pred_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 retak_buaya, 1: 640x640 2 retak_memanjangs, 2: 640x640 3 retak_memanjangs, 3: 640x640 (no detections), 4: 640x640 1 retak_buaya, 5: 640x640 (no detections), 6: 640x640 (no detections), 7: 640x640 3 retak_buayas, 8: 640x640 (no detections), 9: 640x640 (no detections), 10: 640x640 (no detections), 11: 640x640 (no detections), 12: 640x640 (no detections), 13: 640x640 4 retak_memanjangs, 14: 640x640 2 retak_memanjangs, 15: 640x640 (no detections), 16: 640x640 (no detections), 290.2ms\n",
      "Speed: 4.5ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Run inference on an image\n",
    "results = best_model(\n",
    "    source = pred_data\n",
    ")  # list of 1 Results object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    # im.show()  # show image\n",
    "    im.save(pred_location / ('pred_'+Path(r.path).name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r\"D:\\0_amri_local\\14_pupr_roaddamagedetection\\data\\PUPR\\Banten\\21017 R1.mp4\"\n",
    "video_path_out = r\"D:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\notebooks\\out.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "ret, frame = cap.read()\n",
    "H, W, _ = frame.shape\n",
    "out = cv2.VideoWriter(video_path_out, cv2.VideoWriter_fourcc(*'MP4V'), int(cap.get(cv2.CAP_PROP_FPS)), (W, H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "while ret:\n",
    "\n",
    "    results = best_model(frame)[0]\n",
    "\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = result\n",
    "\n",
    "        if score > threshold:\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
    "            cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "    out.write(frame)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8_custom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
