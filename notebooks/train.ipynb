{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path(os.getcwd()).parent\n",
    "\n",
    "data_dir = root_dir/'data'\n",
    "processed_data_dir = data_dir/'1_processed'\n",
    "prediction_dir = data_dir/'2_predictions'\n",
    "yaml_dir = processed_data_dir/'custom_data.yaml'\n",
    "\n",
    "runs_dir = root_dir/'runs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_project = 'custom_runs' # custom run directory\n",
    "data_version = \"3.0\" # for custom run name\n",
    "\n",
    "base_model = \"yolov8m.pt\"\n",
    "base_model_size = base_model.split('.')[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_start = 'pretrained'\n",
    "if model_start == 'pretrained':\n",
    "    pretrained_flag = True\n",
    "else:\n",
    "    pretrained_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_project_dir = root_dir / train_project\n",
    "if cont:\n",
    "    runs_list = os.listdir(custom_project_dir)\n",
    "    last_run = runs_list[-1]\n",
    "else:\n",
    "    # create custom run directory\n",
    "    if not os.path.exists(custom_project_dir):\n",
    "        os.makedirs(custom_project_dir)\n",
    "\n",
    "    # get the list of run\n",
    "    runs_list = os.listdir(custom_project_dir)\n",
    "\n",
    "    # create custom run name\n",
    "    if not runs_list:\n",
    "        train_name = f\"0_{data_version}_{model_start}_{base_model_size}\"\n",
    "    else:\n",
    "        last_run = max([int(order.split('_')[0]) for order in runs_list])\n",
    "        new_run = last_run + 1\n",
    "        train_name = f\"{new_run}_{data_version}_{model_start}_{base_model_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.205 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200  Python-3.9.18 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\\weights\\last.pt, data=d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\data\\1_processed\\custom_data.yaml, epochs=300, patience=10, batch=12, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs, name=2_3.0_pretrained_m, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3778012  ultralytics.nn.modules.head.Detect           [4, [192, 384, 576]]          \n",
      "Model summary: 295 layers, 25858636 parameters, 25858620 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 475/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\data\\1_processed\\train\\labels.cache... 16117 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16117/16117 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\data\\1_processed\\valid\\labels.cache... 4111 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4111/4111 [00:00<?, ?it/s]\n",
      "Plotting labels to d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00046875), 83 bias(decay=0.0)\n",
      "Resuming training from d:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\\weights\\last.pt from epoch 41 to 300 total epochs\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1md:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\custom_runs\\2_3.0_pretrained_m\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/300      5.43G      1.583      1.481      1.504          0        640: 100%|██████████| 1344/1344 [10:36<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:15<00:00,  2.27it/s]\n",
      "                   all       4111       8921      0.635      0.582      0.619      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/300      5.43G        1.6      1.506      1.515          0        640: 100%|██████████| 1344/1344 [11:27<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:15<00:00,  2.29it/s]\n",
      "                   all       4111       8921      0.638      0.581       0.62      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/300      5.42G      1.593      1.502       1.52          1        640: 100%|██████████| 1344/1344 [11:05<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:16<00:00,  2.25it/s]\n",
      "                   all       4111       8921      0.635      0.584       0.62      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/300      5.45G      1.587      1.484      1.515          0        640: 100%|██████████| 1344/1344 [11:12<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:14<00:00,  2.32it/s]\n",
      "                   all       4111       8921      0.633      0.589      0.622      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/300      5.46G      1.593      1.486      1.518          6        640: 100%|██████████| 1344/1344 [11:05<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:15<00:00,  2.29it/s]\n",
      "                   all       4111       8921      0.634      0.592      0.623      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/300      5.44G      1.582      1.484      1.509          3        640: 100%|██████████| 1344/1344 [10:57<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:15<00:00,  2.28it/s]\n",
      "                   all       4111       8921       0.63      0.594      0.624      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/300      5.27G      1.581       1.47      1.512          1        640: 100%|██████████| 1344/1344 [10:59<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:17<00:00,  2.22it/s]\n",
      "                   all       4111       8921      0.629      0.593      0.625      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/300      5.41G      1.575      1.461      1.501          1        640: 100%|██████████| 1344/1344 [11:15<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:18<00:00,  2.20it/s]\n",
      "                   all       4111       8921      0.632      0.595      0.626      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/300      5.46G      1.572      1.448      1.497          1        640: 100%|██████████| 1344/1344 [11:28<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:15<00:00,  2.28it/s]\n",
      "                   all       4111       8921      0.643      0.589      0.627      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/300      5.45G      1.563      1.449      1.493          7        640: 100%|██████████| 1344/1344 [11:19<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:17<00:00,  2.21it/s]\n",
      "                   all       4111       8921      0.643       0.59      0.628      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/300      5.43G      1.565      1.441      1.495          2        640: 100%|██████████| 1344/1344 [11:23<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:18<00:00,  2.19it/s]\n",
      "                   all       4111       8921      0.647      0.591      0.629      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/300      5.24G      1.564      1.428      1.492          2        640: 100%|██████████| 1344/1344 [11:10<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [02:05<00:00,  1.37it/s]\n",
      "                   all       4111       8921      0.641      0.596       0.63      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/300      5.25G      1.556      1.424      1.494          1        640: 100%|██████████| 1344/1344 [15:39<00:00,  1.43it/s]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:11<00:00,  2.42it/s]\n",
      "                   all       4111       8921      0.644      0.594      0.629      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/300      5.46G      1.558      1.405      1.482          1        640: 100%|██████████| 1344/1344 [10:49<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:13<00:00,  2.33it/s]\n",
      "                   all       4111       8921      0.641      0.597       0.63      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/300      5.45G      1.551      1.401      1.478          6        640: 100%|██████████| 1344/1344 [10:55<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:14<00:00,  2.29it/s]\n",
      "                   all       4111       8921      0.642      0.594      0.631      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/300      5.44G      1.544       1.39      1.477          4        640: 100%|██████████| 1344/1344 [11:01<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:14<00:00,  2.31it/s]\n",
      "                   all       4111       8921      0.645      0.597      0.631      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/300      5.27G      1.539      1.391      1.476          2        640: 100%|██████████| 1344/1344 [10:54<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:13<00:00,  2.32it/s]\n",
      "                   all       4111       8921      0.641        0.6      0.631      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/300       5.4G      1.534      1.377      1.472          5        640: 100%|██████████| 1344/1344 [10:55<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:15<00:00,  2.27it/s]\n",
      "                   all       4111       8921      0.644      0.597      0.632      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/300      5.45G      1.527      1.362      1.467          6        640: 100%|██████████| 1344/1344 [10:54<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:14<00:00,  2.32it/s]\n",
      "                   all       4111       8921       0.64      0.599      0.631      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/300      5.44G      1.532      1.358       1.47          4        640: 100%|██████████| 1344/1344 [10:55<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:15<00:00,  2.27it/s]\n",
      "                   all       4111       8921      0.642      0.599      0.632      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/300      5.43G      1.523      1.356      1.462          6        640: 100%|██████████| 1344/1344 [10:57<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:16<00:00,  2.26it/s]\n",
      "                   all       4111       8921      0.638      0.606      0.633      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/300      5.26G      1.524      1.353      1.466          4        640: 100%|██████████| 1344/1344 [10:52<00:00,  2.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:16<00:00,  2.25it/s]\n",
      "                   all       4111       8921      0.636       0.61      0.633      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/300      5.42G      1.511      1.335      1.457          0        640: 100%|██████████| 1344/1344 [10:59<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:13<00:00,  2.34it/s]\n",
      "                   all       4111       8921      0.637      0.612      0.635       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/300      5.45G      1.515      1.326      1.457          7        640: 100%|██████████| 1344/1344 [10:55<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:14<00:00,  2.30it/s]\n",
      "                   all       4111       8921      0.638      0.609      0.635       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/300      5.45G      1.517      1.326      1.454          5        640: 100%|██████████| 1344/1344 [10:54<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:14<00:00,  2.31it/s]\n",
      "                   all       4111       8921      0.638      0.613      0.636       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/300      5.43G      1.506       1.32       1.45          6        640: 100%|██████████| 1344/1344 [10:52<00:00,  2.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:15<00:00,  2.27it/s]\n",
      "                   all       4111       8921       0.64      0.609      0.636       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     67/300      5.27G      1.508      1.307      1.455          3        640: 100%|██████████| 1344/1344 [10:49<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:14<00:00,  2.30it/s]\n",
      "                   all       4111       8921       0.64      0.608      0.635       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     68/300      5.44G      1.493      1.303      1.443          1        640: 100%|██████████| 1344/1344 [15:43<00:00,  1.43it/s] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:11<00:00,  2.39it/s]\n",
      "                   all       4111       8921       0.64      0.609      0.636      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     69/300      5.45G       1.49      1.297      1.437          2        640: 100%|██████████| 1344/1344 [10:38<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:16<00:00,  2.26it/s]\n",
      "                   all       4111       8921      0.641      0.609      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     70/300      5.46G      1.489      1.281      1.436          3        640: 100%|██████████| 1344/1344 [10:52<00:00,  2.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:12<00:00,  2.36it/s]\n",
      "                   all       4111       8921      0.641      0.608      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     71/300      5.47G      1.492      1.285      1.436          6        640: 100%|██████████| 1344/1344 [10:55<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:13<00:00,  2.36it/s]\n",
      "                   all       4111       8921      0.642      0.607      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     72/300      5.27G      1.489      1.274      1.434          1        640: 100%|██████████| 1344/1344 [10:47<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:15<00:00,  2.28it/s]\n",
      "                   all       4111       8921      0.645      0.606      0.638      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     73/300      5.24G       1.49      1.281      1.438          1        640: 100%|██████████| 1344/1344 [10:49<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:16<00:00,  2.26it/s]\n",
      "                   all       4111       8921      0.645      0.606      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     74/300      5.46G      1.474      1.263      1.422          2        640: 100%|██████████| 1344/1344 [10:59<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:14<00:00,  2.30it/s]\n",
      "                   all       4111       8921      0.641      0.607      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     75/300      5.45G      1.471      1.257      1.421          1        640: 100%|██████████| 1344/1344 [11:05<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:15<00:00,  2.26it/s]\n",
      "                   all       4111       8921      0.644      0.606      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     76/300      5.44G      1.468      1.253      1.419          2        640: 100%|██████████| 1344/1344 [12:01<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:17<00:00,  2.23it/s]\n",
      "                   all       4111       8921      0.645      0.607      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     77/300      5.43G      1.462      1.242      1.414          2        640: 100%|██████████| 1344/1344 [12:13<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:15<00:00,  2.27it/s]\n",
      "                   all       4111       8921      0.644      0.609      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     78/300      5.43G      1.468      1.243      1.415          0        640: 100%|██████████| 1344/1344 [12:17<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:18<00:00,  2.18it/s]\n",
      "                   all       4111       8921      0.642      0.608      0.637      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     79/300      5.45G      1.467      1.241      1.414          7        640: 100%|██████████| 1344/1344 [11:28<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:17<00:00,  2.23it/s]\n",
      "                   all       4111       8921      0.641       0.61      0.638      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     80/300      5.45G      1.466      1.244      1.413          4        640: 100%|██████████| 1344/1344 [11:08<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 172/172 [01:16<00:00,  2.26it/s]\n",
      "                   all       4111       8921      0.642       0.61      0.638      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/1344 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\notebooks\\train.ipynb Cell 9\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model \u001b[39m=\u001b[39m YOLO(custom_project_dir \u001b[39m/\u001b[39m last_run \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlast.pt\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# load a partially trained model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# Resume training\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain(resume\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# Load a model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     model \u001b[39m=\u001b[39m YOLO(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         base_model\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/0_amri_local/14_pupr_roaddamagedetection/yolov8_custom/notebooks/train.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\ultralytics\\engine\\model.py:341\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel\n\u001b[0;32m    340\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mhub_session \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession  \u001b[39m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 341\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    342\u001b[0m \u001b[39m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m RANK \u001b[39min\u001b[39;00m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\ultralytics\\engine\\trainer.py:192\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    189\u001b[0m         ddp_cleanup(\u001b[39mself\u001b[39m, \u001b[39mstr\u001b[39m(file))\n\u001b[0;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_train(world_size)\n",
      "File \u001b[1;32mc:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\ultralytics\\engine\\trainer.py:354\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[39m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[39mif\u001b[39;00m ni \u001b[39m-\u001b[39m last_opt_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccumulate:\n\u001b[1;32m--> 354\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer_step()\n\u001b[0;32m    355\u001b[0m     last_opt_step \u001b[39m=\u001b[39m ni\n\u001b[0;32m    357\u001b[0m \u001b[39m# Log\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\ultralytics\\engine\\trainer.py:472\u001b[0m, in \u001b[0;36mBaseTrainer.optimizer_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Perform a single step of the training optimizer with gradient clipping and EMA update.\"\"\"\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39munscale_(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer)  \u001b[39m# unscale gradients\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mclip_grad_norm_(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mparameters(), max_norm\u001b[39m=\u001b[39;49m\u001b[39m10.0\u001b[39;49m)  \u001b[39m# clip gradients\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mstep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer)\n\u001b[0;32m    474\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\arasyidi\\AppData\\Local\\miniconda3\\envs\\yolov8_custom\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:76\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mfor\u001b[39;00m ((device, _), [grads]) \u001b[39min\u001b[39;00m grouped_grads\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m (foreach \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m foreach) \u001b[39mand\u001b[39;00m _has_foreach_support(grads, device\u001b[39m=\u001b[39mdevice):\n\u001b[1;32m---> 76\u001b[0m         torch\u001b[39m.\u001b[39;49m_foreach_mul_(grads, clip_coef_clamped\u001b[39m.\u001b[39;49mto(device))  \u001b[39m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[39melif\u001b[39;00m foreach:\n\u001b[0;32m     78\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mforeach=True was passed, but can\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mt use the foreach API on \u001b[39m\u001b[39m{\u001b[39;00mdevice\u001b[39m.\u001b[39mtype\u001b[39m}\u001b[39;00m\u001b[39m tensors\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if cont:\n",
    "    # Load a model\n",
    "    model = YOLO(custom_project_dir / last_run / 'weights' / 'last.pt')  # load a partially trained model\n",
    "\n",
    "    # Resume training\n",
    "    results = model.train(resume=True)\n",
    "else:\n",
    "    # Load a model\n",
    "    model = YOLO(\n",
    "        base_model\n",
    "        )\n",
    "\n",
    "    # train the model\n",
    "    results = model.train(\n",
    "        data=yaml_dir,\n",
    "        epochs=300,\n",
    "        batch=12,\n",
    "        patience=10,\n",
    "        project=custom_project_dir,\n",
    "        name=train_name,\n",
    "        pretrained=pretrained_flag\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained YOLOv8n model\n",
    "best_model = YOLO(custom_project_dir / train_name / \"weights\" / \"best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = [str(prediction_dir / \"original\" / file) for file in os.listdir(prediction_dir / \"original\")]\n",
    "\n",
    "pred_location = prediction_dir / train_name\n",
    "if not os.path.exists(pred_location):\n",
    "    os.makedirs(pred_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 retak_buaya, 1: 640x640 2 retak_memanjangs, 2: 640x640 3 retak_memanjangs, 3: 640x640 (no detections), 4: 640x640 1 retak_buaya, 5: 640x640 (no detections), 6: 640x640 (no detections), 7: 640x640 3 retak_buayas, 8: 640x640 (no detections), 9: 640x640 (no detections), 10: 640x640 (no detections), 11: 640x640 (no detections), 12: 640x640 (no detections), 13: 640x640 4 retak_memanjangs, 14: 640x640 2 retak_memanjangs, 15: 640x640 (no detections), 16: 640x640 (no detections), 290.2ms\n",
      "Speed: 4.5ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Run inference on an image\n",
    "results = best_model(\n",
    "    source = pred_data\n",
    ")  # list of 1 Results object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    # im.show()  # show image\n",
    "    im.save(pred_location / ('pred_'+Path(r.path).name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r\"D:\\0_amri_local\\14_pupr_roaddamagedetection\\data\\PUPR\\Banten\\21017 R1.mp4\"\n",
    "video_path_out = r\"D:\\0_amri_local\\14_pupr_roaddamagedetection\\yolov8_custom\\notebooks\\out.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "ret, frame = cap.read()\n",
    "H, W, _ = frame.shape\n",
    "out = cv2.VideoWriter(video_path_out, cv2.VideoWriter_fourcc(*'MP4V'), int(cap.get(cv2.CAP_PROP_FPS)), (W, H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "while ret:\n",
    "\n",
    "    results = best_model(frame)[0]\n",
    "\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = result\n",
    "\n",
    "        if score > threshold:\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
    "            cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "    out.write(frame)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8_custom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
